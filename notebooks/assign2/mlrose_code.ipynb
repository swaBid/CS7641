{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed483a-d172-4999-8ad6-8c25fb5bd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Classes for defining decay schedules for simulated annealing.\"\"\"\n",
    "\n",
    "# Author: Genevieve Hayes\n",
    "# License: BSD 3 clause\n",
    "\n",
    "class FourPeaks:\n",
    "    \"\"\"Fitness function for Four Peaks optimization problem. Evaluates the\n",
    "    fitness of an n-dimensional state vector :math:`x`, given parameter T, as:\n",
    "\n",
    "    .. math::\n",
    "        Fitness(x, T) = \\\\max(tail(0, x), head(1, x)) + R(x, T)\n",
    "\n",
    "    where:\n",
    "\n",
    "    * :math:`tail(b, x)` is the number of trailing b's in :math:`x`;\n",
    "    * :math:`head(b, x)` is the number of leading b's in :math:`x`;\n",
    "    * :math:`R(x, T) = n`, if :math:`tail(0, x) > T` and\n",
    "      :math:`head(1, x) > T`; and\n",
    "    * :math:`R(x, T) = 0`, otherwise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t_pct: float, default: 0.1\n",
    "        Threshold parameter (T) for Four Peaks fitness function, expressed as\n",
    "        a percentage of the state space dimension, n (i.e.\n",
    "        :math:`T = t_{pct} \\\\times n`).\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    .. highlight:: python\n",
    "    .. code-block:: python\n",
    "\n",
    "        >>> import mlrose\n",
    "        >>> import numpy as np\n",
    "        >>> fitness = mlrose.FourPeaks(t_pct=0.15)\n",
    "        >>> state = np.array([1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
    "        >>> fitness.evaluate(state)\n",
    "        16\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    De Bonet, J., C. Isbell, and P. Viola (1997). MIMIC: Finding Optima by\n",
    "    Estimating Probability Densities. In *Advances in Neural Information\n",
    "    Processing Systems* (NIPS) 9, pp. 424â€“430.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    The Four Peaks fitness function is suitable for use in bit-string\n",
    "    (discrete-state with :code:`max_val = 2`) optimization problems *only*.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, t_pct=0.1):\n",
    "\n",
    "        self.t_pct = t_pct\n",
    "        self.prob_type = 'discrete'\n",
    "        self.leng=leng\n",
    "\n",
    "        if (self.t_pct < 0) or (self.t_pct > 1):\n",
    "            raise Exception(\"\"\"t_pct must be between 0 and 1.\"\"\")\n",
    "\n",
    "    def get_length(self):\n",
    "        return self.leng\n",
    "    \n",
    "    def evaluate(self, state):\n",
    "        \"\"\"Evaluate the fitness of a state vector.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state: array\n",
    "            State array for evaluation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fitness: float.\n",
    "            Value of fitness function.\n",
    "        \"\"\"\n",
    "        _n = len(state)\n",
    "        _t = np.ceil(self.t_pct*_n)\n",
    "\n",
    "        # Calculate head and tail values\n",
    "        tail_0 = tail(0, state)\n",
    "        head_1 = head(1, state)\n",
    "\n",
    "        # Calculate R(X, T)\n",
    "        if (tail_0 > _t and head_1 > _t):\n",
    "            _r = _n\n",
    "        else:\n",
    "            _r = 0\n",
    "\n",
    "        # Evaluate function\n",
    "        fitness = max(tail_0, head_1) + _r\n",
    "\n",
    "        return fitness\n",
    "\n",
    "\n",
    "    def get_prob_type(self):\n",
    "        \"\"\" Return the problem type.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self.prob_type: string\n",
    "            Specifies problem type as 'discrete', 'continuous', 'tsp'\n",
    "            or 'either'.\n",
    "        \"\"\"\n",
    "        return self.prob_type\n",
    "\n",
    "class GeomDecay:\n",
    "    \"\"\"\n",
    "    Schedule for geometrically decaying the simulated\n",
    "    annealing temperature parameter T according to the formula:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        T(t) = \\\\max(T_{0} \\\\times r^{t}, T_{min})\n",
    "\n",
    "    where:\n",
    "\n",
    "    * :math:`T_{0}` is the initial temperature (at time t = 0);\n",
    "    * :math:`r` is the rate of geometric decay; and\n",
    "    * :math:`T_{min}` is the minimum temperature value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_temp: float, default: 1.0\n",
    "        Initial value of temperature parameter T. Must be greater than 0.\n",
    "    decay: float, default: 0.99\n",
    "        Temperature decay parameter, r. Must be between 0 and 1.\n",
    "    min_temp: float, default: 0.001\n",
    "        Minimum value of temperature parameter. Must be greater than 0.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    .. highlight:: python\n",
    "    .. code-block:: python\n",
    "\n",
    "        >>> import mlrose\n",
    "        >>> schedule = mlrose.GeomDecay(init_temp=10, decay=0.95, min_temp=1)\n",
    "        >>> schedule.evaluate(5)\n",
    "        7.73780...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_temp=1.0, decay=0.99, min_temp=0.001):\n",
    "\n",
    "        self.init_temp = init_temp\n",
    "        self.decay = decay\n",
    "        self.min_temp = min_temp\n",
    "\n",
    "        if self.init_temp <= 0:\n",
    "            raise Exception(\"\"\"init_temp must be greater than 0.\"\"\")\n",
    "\n",
    "        if (self.decay <= 0) or (self.decay > 1):\n",
    "            raise Exception(\"\"\"decay must be between 0 and 1.\"\"\")\n",
    "\n",
    "        if self.min_temp < 0:\n",
    "            raise Exception(\"\"\"min_temp must be greater than 0.\"\"\")\n",
    "        elif self.min_temp > self.init_temp:\n",
    "            raise Exception(\"\"\"init_temp must be greater than min_temp.\"\"\")\n",
    "\n",
    "    def evaluate(self, t):\n",
    "        \"\"\"Evaluate the temperature parameter at time t.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t: int\n",
    "            Time at which the temperature paramter T is evaluated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        temp: float\n",
    "            Temperature parameter at time t.\n",
    "        \"\"\"\n",
    "\n",
    "        temp = self.init_temp*(self.decay**t)\n",
    "\n",
    "        if temp < self.min_temp:\n",
    "            temp = self.min_temp\n",
    "\n",
    "        return temp\n",
    "\n",
    "\n",
    "\n",
    "class ArithDecay:\n",
    "    \"\"\"\n",
    "    Schedule for arithmetically decaying the simulated\n",
    "    annealing temperature parameter T according to the formula:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        T(t) = \\\\max(T_{0} - rt, T_{min})\n",
    "\n",
    "    where:\n",
    "\n",
    "    * :math:`T_{0}` is the initial temperature (at time t = 0);\n",
    "    * :math:`r` is the rate of arithmetic decay; and\n",
    "    * :math:`T_{min}` is the minimum temperature value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_temp: float, default: 1.0\n",
    "        Initial value of temperature parameter T. Must be greater than 0.\n",
    "    decay: float, default: 0.0001\n",
    "        Temperature decay parameter, r. Must be greater than 0.\n",
    "    min_temp: float, default: 0.001\n",
    "        Minimum value of temperature parameter. Must be greater than 0.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    .. highlight:: python\n",
    "    .. code-block:: python\n",
    "\n",
    "        >>> import mlrose\n",
    "        >>> schedule = mlrose.ArithDecay(init_temp=10, decay=0.95, min_temp=1)\n",
    "        >>> schedule.evaluate(5)\n",
    "        5.25\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_temp=1.0, decay=0.0001, min_temp=0.001):\n",
    "\n",
    "        self.init_temp = init_temp\n",
    "        self.decay = decay\n",
    "        self.min_temp = min_temp\n",
    "\n",
    "        if self.init_temp <= 0:\n",
    "            raise Exception(\"\"\"init_temp must be greater than 0.\"\"\")\n",
    "\n",
    "        if (self.decay <= 0) or (self.decay > 1):\n",
    "            raise Exception(\"\"\"decay must be greater than 0.\"\"\")\n",
    "\n",
    "        if self.min_temp < 0:\n",
    "            raise Exception(\"\"\"min_temp must be greater than 0.\"\"\")\n",
    "        elif self.min_temp > self.init_temp:\n",
    "            raise Exception(\"\"\"init_temp must be greater than min_temp.\"\"\")\n",
    "\n",
    "    def evaluate(self, t):\n",
    "        \"\"\"Evaluate the temperature parameter at time t.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t: int\n",
    "            Time at which the temperature paramter T is evaluated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        temp: float\n",
    "            Temperature parameter at time t.\n",
    "        \"\"\"\n",
    "\n",
    "        temp = self.init_temp - (self.decay*t)\n",
    "\n",
    "        if temp < self.min_temp:\n",
    "            temp = self.min_temp\n",
    "\n",
    "        return temp\n",
    "\n",
    "\n",
    "\n",
    "class ExpDecay:\n",
    "    \"\"\"\n",
    "    Schedule for exponentially decaying the simulated\n",
    "    annealing temperature parameter T according to the formula:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        T(t) = \\\\max(T_{0} e^{-rt}, T_{min})\n",
    "\n",
    "    where:\n",
    "\n",
    "    * :math:`T_{0}` is the initial temperature (at time t = 0);\n",
    "    * :math:`r` is the rate of exponential decay; and\n",
    "    * :math:`T_{min}` is the minimum temperature value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_temp: float, default: 1.0\n",
    "        Initial value of temperature parameter T. Must be greater than 0.\n",
    "    exp_const: float, default: 0.005\n",
    "        Exponential constant parameter, r. Must be greater than 0.\n",
    "    min_temp: float, default: 0.001\n",
    "        Minimum value of temperature parameter. Must be greater than 0.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    .. highlight:: python\n",
    "    .. code-block:: python\n",
    "\n",
    "       >>> import mlrose\n",
    "       >>> schedule = mlrose.ExpDecay(init_temp=10, exp_const=0.05, min_temp=1)\n",
    "       >>> schedule.evaluate(5)\n",
    "       7.78800...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_temp=1.0, exp_const=0.005, min_temp=0.001):\n",
    "\n",
    "        self.init_temp = init_temp\n",
    "        self.exp_const = exp_const\n",
    "        self.min_temp = min_temp\n",
    "\n",
    "        if self.init_temp <= 0:\n",
    "            raise Exception(\"\"\"init_temp must be greater than 0.\"\"\")\n",
    "\n",
    "        if self.exp_const <= 0:\n",
    "            raise Exception(\"\"\"exp_const must be greater than 0.\"\"\")\n",
    "\n",
    "        if self.min_temp < 0:\n",
    "            raise Exception(\"\"\"min_temp must be greater than 0.\"\"\")\n",
    "        elif self.min_temp > self.init_temp:\n",
    "            raise Exception(\"\"\"init_temp must be greater than min_temp.\"\"\")\n",
    "\n",
    "    def evaluate(self, t):\n",
    "        \"\"\"Evaluate the temperature parameter at time t.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t: int\n",
    "            Time at which the temperature paramter T is evaluated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        temp: float\n",
    "            Temperature parameter at time t.\n",
    "        \"\"\"\n",
    "\n",
    "        temp = self.init_temp*np.exp(-1.0*self.exp_const*t)\n",
    "\n",
    "        if temp < self.min_temp:\n",
    "            temp = self.min_temp\n",
    "\n",
    "        return temp\n",
    "\n",
    "\n",
    "\n",
    "class CustomSchedule:\n",
    "    \"\"\"Class for generating your own temperature schedule.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    schedule: callable\n",
    "        Function for calculating the temperature at time t with the signature\n",
    "        :code:`schedule(t, **kwargs)`.\n",
    "\n",
    "    kwargs: additional arguments\n",
    "        Additional parameters to be passed to schedule.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    .. highlight:: python\n",
    "    .. code-block:: python\n",
    "\n",
    "        >>> import mlrose\n",
    "        >>> def custom(t, c): return t + c\n",
    "        >>> kwargs = {'c': 10}\n",
    "        >>> schedule = mlrose.CustomSchedule(custom, **kwargs)\n",
    "        >>> schedule.evaluate(5)\n",
    "        15\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, schedule, **kwargs):\n",
    "\n",
    "        self.schedule = schedule\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def evaluate(self, t):\n",
    "        \"\"\"Evaluate the temperature parameter at time t.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t: int\n",
    "            Time at which the temperature paramter T is evaluated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        temp: float\n",
    "            Temperature parameter at time t.\n",
    "        \"\"\"\n",
    "\n",
    "        temp = self.schedule(t, **self.kwargs)\n",
    "        return temp\n",
    "\n",
    "\n",
    "\"\"\" Functions to implement the randomized optimization and search algorithms.\n",
    "\"\"\"\n",
    "\n",
    "# Author: Genevieve Hayes\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "#from .decay import GeomDecay\n",
    "\n",
    "\n",
    "def hill_climb(problem, max_iters=np.inf, restarts=0, init_state=None,\n",
    "               curve=False, random_state=None):\n",
    "    \"\"\"Use standard hill climbing to find the optimum for a given\n",
    "    optimization problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem: optimization object\n",
    "        Object containing fitness function optimization problem to be solved.\n",
    "        For example, :code:`DiscreteOpt()`, :code:`ContinuousOpt()` or\n",
    "        :code:`TSPOpt()`.\n",
    "    max_iters: int, default: np.inf\n",
    "        Maximum number of iterations of the algorithm for each restart.\n",
    "    restarts: int, default: 0\n",
    "        Number of random restarts.\n",
    "    init_state: array, default: None\n",
    "        1-D Numpy array containing starting state for algorithm.\n",
    "        If :code:`None`, then a random state is used.\n",
    "    curve: bool, default: False\n",
    "        Boolean to keep fitness values for a curve.\n",
    "        If :code:`False`, then no curve is stored.\n",
    "        If :code:`True`, then a history of fitness values is provided as a\n",
    "        third return value.\n",
    "    random_state: int, default: None\n",
    "        If random_state is a positive integer, random_state is the seed used\n",
    "        by np.random.seed(); otherwise, the random seed is not set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_state: array\n",
    "        Numpy array containing state that optimizes the fitness function.\n",
    "    best_fitness: float\n",
    "        Value of fitness function at best state.\n",
    "    fitness_curve: array\n",
    "        Numpy array containing the fitness at every iteration.\n",
    "        Only returned if input argument :code:`curve` is :code:`True`.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Russell, S. and P. Norvig (2010). *Artificial Intelligence: A Modern\n",
    "    Approach*, 3rd edition. Prentice Hall, New Jersey, USA.\n",
    "    \"\"\"\n",
    "    if (not isinstance(max_iters, int) and max_iters != np.inf\n",
    "            and not max_iters.is_integer()) or (max_iters < 0):\n",
    "        raise Exception(\"\"\"max_iters must be a positive integer.\"\"\")\n",
    "\n",
    "    if (not isinstance(restarts, int) and not restarts.is_integer()) \\\n",
    "       or (restarts < 0):\n",
    "        raise Exception(\"\"\"restarts must be a positive integer.\"\"\")\n",
    "\n",
    "    if init_state is not None and len(init_state) != problem.get_length():\n",
    "        raise Exception(\"\"\"init_state must have same length as problem.\"\"\")\n",
    "\n",
    "    # Set random seed\n",
    "    if isinstance(random_state, int) and random_state > 0:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    best_fitness = -1*np.inf\n",
    "    best_state = None\n",
    "\n",
    "    if curve:\n",
    "        fitness_curve = []\n",
    "\n",
    "    for _ in range(restarts + 1):\n",
    "        # Initialize optimization problem\n",
    "        if init_state is None:\n",
    "            problem.reset()\n",
    "        else:\n",
    "            problem.set_state(init_state)\n",
    "\n",
    "        iters = 0\n",
    "\n",
    "        while iters < max_iters:\n",
    "            iters += 1\n",
    "\n",
    "            # Find neighbors and determine best neighbor\n",
    "            problem.find_neighbors()\n",
    "            next_state = problem.best_neighbor()\n",
    "            next_fitness = problem.eval_fitness(next_state)\n",
    "\n",
    "            # If best neighbor is an improvement, move to that state\n",
    "            if next_fitness > problem.get_fitness():\n",
    "                problem.set_state(next_state)\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            if curve:\n",
    "                fitness_curve.append(problem.get_fitness())\n",
    "\n",
    "        # Update best state and best fitness\n",
    "        if problem.get_fitness() > best_fitness:\n",
    "            best_fitness = problem.get_fitness()\n",
    "            best_state = problem.get_state()\n",
    "\n",
    "    best_fitness = problem.get_maximize()*best_fitness\n",
    "\n",
    "    if curve:\n",
    "        return best_state, best_fitness, np.asarray(fitness_curve)\n",
    "\n",
    "    return best_state, best_fitness\n",
    "\n",
    "\n",
    "\n",
    "def random_hill_climb(problem, max_attempts=10, max_iters=np.inf, restarts=0,\n",
    "                      init_state=None, curve=False, random_state=None):\n",
    "    \"\"\"Use randomized hill climbing to find the optimum for a given\n",
    "    optimization problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem: optimization object\n",
    "        Object containing fitness function optimization problem to be solved.\n",
    "        For example, :code:`DiscreteOpt()`, :code:`ContinuousOpt()` or\n",
    "        :code:`TSPOpt()`.\n",
    "    max_attempts: int, default: 10\n",
    "        Maximum number of attempts to find a better neighbor at each step.\n",
    "    max_iters: int, default: np.inf\n",
    "        Maximum number of iterations of the algorithm.\n",
    "    restarts: int, default: 0\n",
    "        Number of random restarts.\n",
    "    init_state: array, default: None\n",
    "        1-D Numpy array containing starting state for algorithm.\n",
    "        If :code:`None`, then a random state is used.\n",
    "    curve: bool, default: False\n",
    "        Boolean to keep fitness values for a curve.\n",
    "        If :code:`False`, then no curve is stored.\n",
    "        If :code:`True`, then a history of fitness values is provided as a\n",
    "        third return value.\n",
    "    random_state: int, default: None\n",
    "        If random_state is a positive integer, random_state is the seed used\n",
    "        by np.random.seed(); otherwise, the random seed is not set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_state: array\n",
    "        Numpy array containing state that optimizes the fitness function.\n",
    "    best_fitness: float\n",
    "        Value of fitness function at best state.\n",
    "    fitness_curve: array\n",
    "        Numpy array containing the fitness at every iteration.\n",
    "        Only returned if input argument :code:`curve` is :code:`True`.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Brownlee, J (2011). *Clever Algorithms: Nature-Inspired Programming\n",
    "    Recipes*. `<http://www.cleveralgorithms.com>`_.\n",
    "    \"\"\"\n",
    "    if (not isinstance(max_attempts, int) and not max_attempts.is_integer()) \\\n",
    "       or (max_attempts < 0):\n",
    "        raise Exception(\"\"\"max_attempts must be a positive integer.\"\"\")\n",
    "\n",
    "    if (not isinstance(max_iters, int) and max_iters != np.inf\n",
    "            and not max_iters.is_integer()) or (max_iters < 0):\n",
    "        raise Exception(\"\"\"max_iters must be a positive integer.\"\"\")\n",
    "\n",
    "    if (not isinstance(restarts, int) and not restarts.is_integer()) \\\n",
    "       or (restarts < 0):\n",
    "        raise Exception(\"\"\"restarts must be a positive integer.\"\"\")\n",
    "\n",
    "    if init_state is not None and len(init_state) != problem.get_length():\n",
    "        raise Exception(\"\"\"init_state must have same length as problem.\"\"\")\n",
    "\n",
    "    # Set random seed\n",
    "    if isinstance(random_state, int) and random_state > 0:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    best_fitness = -1*np.inf\n",
    "    best_state = None\n",
    "\n",
    "    if curve:\n",
    "        fitness_curve = []\n",
    "\n",
    "    for _ in range(restarts + 1):\n",
    "        # Initialize optimization problem and attempts counter\n",
    "        if init_state is None:\n",
    "            problem.reset()\n",
    "        else:\n",
    "            problem.set_state(init_state)\n",
    "\n",
    "        attempts = 0\n",
    "        iters = 0\n",
    "\n",
    "        while (attempts < max_attempts) and (iters < max_iters):\n",
    "            iters += 1\n",
    "\n",
    "            # Find random neighbor and evaluate fitness\n",
    "            next_state = problem.random_neighbor()\n",
    "            next_fitness = problem.eval_fitness(next_state)\n",
    "\n",
    "            # If best neighbor is an improvement,\n",
    "            # move to that state and reset attempts counter\n",
    "            if next_fitness > problem.get_fitness():\n",
    "                problem.set_state(next_state)\n",
    "                attempts = 0\n",
    "\n",
    "            else:\n",
    "                attempts += 1\n",
    "\n",
    "            if curve:\n",
    "                fitness_curve.append(problem.get_fitness())\n",
    "\n",
    "        # Update best state and best fitness\n",
    "        if problem.get_fitness() > best_fitness:\n",
    "            best_fitness = problem.get_fitness()\n",
    "            best_state = problem.get_state()\n",
    "\n",
    "    best_fitness = problem.get_maximize()*best_fitness\n",
    "\n",
    "    if curve:\n",
    "        return best_state, best_fitness, np.asarray(fitness_curve)\n",
    "\n",
    "    return best_state, best_fitness\n",
    "\n",
    "\n",
    "\n",
    "def simulated_annealing(problem, schedule=GeomDecay(), max_attempts=10,\n",
    "                        max_iters=np.inf, init_state=None, curve=False,\n",
    "                        random_state=None):\n",
    "    \"\"\"Use simulated annealing to find the optimum for a given\n",
    "    optimization problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem: optimization object\n",
    "        Object containing fitness function optimization problem to be solved.\n",
    "        For example, :code:`DiscreteOpt()`, :code:`ContinuousOpt()` or\n",
    "        :code:`TSPOpt()`.\n",
    "    schedule: schedule object, default: :code:`mlrose.GeomDecay()`\n",
    "        Schedule used to determine the value of the temperature parameter.\n",
    "    max_attempts: int, default: 10\n",
    "        Maximum number of attempts to find a better neighbor at each step.\n",
    "    max_iters: int, default: np.inf\n",
    "        Maximum number of iterations of the algorithm.\n",
    "    init_state: array, default: None\n",
    "        1-D Numpy array containing starting state for algorithm.\n",
    "        If :code:`None`, then a random state is used.\n",
    "    curve: bool, default: False\n",
    "        Boolean to keep fitness values for a curve.\n",
    "        If :code:`False`, then no curve is stored.\n",
    "        If :code:`True`, then a history of fitness values is provided as a\n",
    "        third return value.\n",
    "    random_state: int, default: None\n",
    "        If random_state is a positive integer, random_state is the seed used\n",
    "        by np.random.seed(); otherwise, the random seed is not set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_state: array\n",
    "        Numpy array containing state that optimizes the fitness function.\n",
    "    best_fitness: float\n",
    "        Value of fitness function at best state.\n",
    "    fitness_curve: array\n",
    "        Numpy array containing the fitness at every iteration.\n",
    "        Only returned if input argument :code:`curve` is :code:`True`.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Russell, S. and P. Norvig (2010). *Artificial Intelligence: A Modern\n",
    "    Approach*, 3rd edition. Prentice Hall, New Jersey, USA.\n",
    "    \"\"\"\n",
    "    if (not isinstance(max_attempts, int) and not max_attempts.is_integer()) \\\n",
    "       or (max_attempts < 0):\n",
    "        raise Exception(\"\"\"max_attempts must be a positive integer.\"\"\")\n",
    "\n",
    "    if (not isinstance(max_iters, int) and max_iters != np.inf\n",
    "            and not max_iters.is_integer()) or (max_iters < 0):\n",
    "        raise Exception(\"\"\"max_iters must be a positive integer.\"\"\")\n",
    "\n",
    "    if init_state is not None and len(init_state) != problem.get_length():\n",
    "        raise Exception(\"\"\"init_state must have same length as problem.\"\"\")\n",
    "\n",
    "    # Set random seed\n",
    "    if isinstance(random_state, int) and random_state > 0:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Initialize problem, time and attempts counter\n",
    "    if init_state is None:\n",
    "        problem.reset()\n",
    "    else:\n",
    "        problem.set_state(init_state)\n",
    "\n",
    "    if curve:\n",
    "        fitness_curve = []\n",
    "\n",
    "    attempts = 0\n",
    "    iters = 0\n",
    "\n",
    "    while (attempts < max_attempts) and (iters < max_iters):\n",
    "        temp = schedule.evaluate(iters)\n",
    "        iters += 1\n",
    "\n",
    "        if temp == 0:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            # Find random neighbor and evaluate fitness\n",
    "            next_state = problem.random_neighbor()\n",
    "            next_fitness = problem.eval_fitness(next_state)\n",
    "\n",
    "            # Calculate delta E and change prob\n",
    "            delta_e = next_fitness - problem.get_fitness()\n",
    "            prob = np.exp(delta_e/temp)\n",
    "\n",
    "            # If best neighbor is an improvement or random value is less\n",
    "            # than prob, move to that state and reset attempts counter\n",
    "            if (delta_e > 0) or (np.random.uniform() < prob):\n",
    "                problem.set_state(next_state)\n",
    "                attempts = 0\n",
    "\n",
    "            else:\n",
    "                attempts += 1\n",
    "\n",
    "        if curve:\n",
    "            fitness_curve.append(problem.get_fitness())\n",
    "\n",
    "    best_fitness = problem.get_maximize()*problem.get_fitness()\n",
    "    best_state = problem.get_state()\n",
    "\n",
    "    if curve:\n",
    "        return best_state, best_fitness, np.asarray(fitness_curve)\n",
    "\n",
    "    return best_state, best_fitness\n",
    "\n",
    "\n",
    "\n",
    "def genetic_alg(problem, pop_size=200, mutation_prob=0.1, max_attempts=10,\n",
    "                max_iters=np.inf, curve=False, random_state=None):\n",
    "    \"\"\"Use a standard genetic algorithm to find the optimum for a given\n",
    "    optimization problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem: optimization object\n",
    "        Object containing fitness function optimization problem to be solved.\n",
    "        For example, :code:`DiscreteOpt()`, :code:`ContinuousOpt()` or\n",
    "        :code:`TSPOpt()`.\n",
    "    pop_size: int, default: 200\n",
    "        Size of population to be used in genetic algorithm.\n",
    "    mutation_prob: float, default: 0.1\n",
    "        Probability of a mutation at each element of the state vector\n",
    "        during reproduction, expressed as a value between 0 and 1.\n",
    "    max_attempts: int, default: 10\n",
    "        Maximum number of attempts to find a better state at each step.\n",
    "    max_iters: int, default: np.inf\n",
    "        Maximum number of iterations of the algorithm.\n",
    "    curve: bool, default: False\n",
    "        Boolean to keep fitness values for a curve.\n",
    "        If :code:`False`, then no curve is stored.\n",
    "        If :code:`True`, then a history of fitness values is provided as a\n",
    "        third return value.\n",
    "    random_state: int, default: None\n",
    "        If random_state is a positive integer, random_state is the seed used\n",
    "        by np.random.seed(); otherwise, the random seed is not set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_state: array\n",
    "        Numpy array containing state that optimizes the fitness function.\n",
    "    best_fitness: float\n",
    "        Value of fitness function at best state.\n",
    "    fitness_curve: array\n",
    "        Numpy array of arrays containing the fitness of the entire population\n",
    "        at every iteration.\n",
    "        Only returned if input argument :code:`curve` is :code:`True`.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Russell, S. and P. Norvig (2010). *Artificial Intelligence: A Modern\n",
    "    Approach*, 3rd edition. Prentice Hall, New Jersey, USA.\n",
    "    \"\"\"\n",
    "    if pop_size < 0:\n",
    "        raise Exception(\"\"\"pop_size must be a positive integer.\"\"\")\n",
    "    elif not isinstance(pop_size, int):\n",
    "        if pop_size.is_integer():\n",
    "            pop_size = int(pop_size)\n",
    "        else:\n",
    "            raise Exception(\"\"\"pop_size must be a positive integer.\"\"\")\n",
    "\n",
    "    if (mutation_prob < 0) or (mutation_prob > 1):\n",
    "        raise Exception(\"\"\"mutation_prob must be between 0 and 1.\"\"\")\n",
    "\n",
    "    if (not isinstance(max_attempts, int) and not max_attempts.is_integer()) \\\n",
    "       or (max_attempts < 0):\n",
    "        raise Exception(\"\"\"max_attempts must be a positive integer.\"\"\")\n",
    "\n",
    "    if (not isinstance(max_iters, int) and max_iters != np.inf\n",
    "            and not max_iters.is_integer()) or (max_iters < 0):\n",
    "        raise Exception(\"\"\"max_iters must be a positive integer.\"\"\")\n",
    "\n",
    "    # Set random seed\n",
    "    if isinstance(random_state, int) and random_state > 0:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    if curve:\n",
    "        fitness_curve = []\n",
    "\n",
    "    # Initialize problem, population and attempts counter\n",
    "    problem.reset()\n",
    "    problem.random_pop(pop_size)\n",
    "    attempts = 0\n",
    "    iters = 0\n",
    "\n",
    "    while (attempts < max_attempts) and (iters < max_iters):\n",
    "        iters += 1\n",
    "\n",
    "        # Calculate breeding probabilities\n",
    "        problem.eval_mate_probs()\n",
    "\n",
    "        # Create next generation of population\n",
    "        next_gen = []\n",
    "\n",
    "        for _ in range(pop_size):\n",
    "            # Select parents\n",
    "            selected = np.random.choice(pop_size, size=2,\n",
    "                                        p=problem.get_mate_probs())\n",
    "            parent_1 = problem.get_population()[selected[0]]\n",
    "            parent_2 = problem.get_population()[selected[1]]\n",
    "\n",
    "            # Create offspring\n",
    "            child = problem.reproduce(parent_1, parent_2, mutation_prob)\n",
    "            next_gen.append(child)\n",
    "\n",
    "        next_gen = np.array(next_gen)\n",
    "        problem.set_population(next_gen)\n",
    "\n",
    "        next_state = problem.best_child()\n",
    "        next_fitness = problem.eval_fitness(next_state)\n",
    "\n",
    "        # If best child is an improvement,\n",
    "        # move to that state and reset attempts counter\n",
    "        if next_fitness > problem.get_fitness():\n",
    "            problem.set_state(next_state)\n",
    "            attempts = 0\n",
    "\n",
    "        else:\n",
    "            attempts += 1\n",
    "\n",
    "        if curve:\n",
    "            fitness_curve.append(problem.get_fitness())\n",
    "\n",
    "    best_fitness = problem.get_maximize()*problem.get_fitness()\n",
    "    best_state = problem.get_state()\n",
    "\n",
    "    if curve:\n",
    "        return best_state, best_fitness, np.asarray(fitness_curve)\n",
    "\n",
    "    return best_state, best_fitness\n",
    "\n",
    "\n",
    "\n",
    "def mimic(problem, pop_size=200, keep_pct=0.2, max_attempts=10,\n",
    "          max_iters=np.inf, curve=False, random_state=None, fast_mimic=False):\n",
    "    \"\"\"Use MIMIC to find the optimum for a given optimization problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem: optimization object\n",
    "        Object containing fitness function optimization problem to be solved.\n",
    "        For example, :code:`DiscreteOpt()` or :code:`TSPOpt()`.\n",
    "    pop_size: int, default: 200\n",
    "        Size of population to be used in algorithm.\n",
    "    keep_pct: float, default: 0.2\n",
    "        Proportion of samples to keep at each iteration of the algorithm,\n",
    "        expressed as a value between 0 and 1.\n",
    "    max_attempts: int, default: 10\n",
    "        Maximum number of attempts to find a better neighbor at each step.\n",
    "    max_iters: int, default: np.inf\n",
    "        Maximum number of iterations of the algorithm.\n",
    "    curve: bool, default: False\n",
    "        Boolean to keep fitness values for a curve.\n",
    "        If :code:`False`, then no curve is stored.\n",
    "        If :code:`True`, then a history of fitness values is provided as a\n",
    "        third return value.\n",
    "    random_state: int, default: None\n",
    "        If random_state is a positive integer, random_state is the seed used\n",
    "        by np.random.seed(); otherwise, the random seed is not set.\n",
    "    fast_mimic: bool, default: False\n",
    "        Activate fast mimic mode to compute the mutual information in\n",
    "        vectorized form. Faster speed but requires more memory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_state: array\n",
    "        Numpy array containing state that optimizes the fitness function.\n",
    "    best_fitness: float\n",
    "        Value of fitness function at best state.\n",
    "    fitness_curve: array\n",
    "        Numpy array containing the fitness at every iteration.\n",
    "        Only returned if input argument :code:`curve` is :code:`True`.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    De Bonet, J., C. Isbell, and P. Viola (1997). MIMIC: Finding Optima by\n",
    "    Estimating Probability Densities. In *Advances in Neural Information\n",
    "    Processing Systems* (NIPS) 9, pp. 424â€“430.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    MIMIC cannot be used for solving continuous-state optimization problems.\n",
    "    \"\"\"\n",
    "    if problem.get_prob_type() == 'continuous':\n",
    "        raise Exception(\"\"\"problem type must be discrete or tsp.\"\"\")\n",
    "\n",
    "    if pop_size < 0:\n",
    "        raise Exception(\"\"\"pop_size must be a positive integer.\"\"\")\n",
    "    elif not isinstance(pop_size, int):\n",
    "        if pop_size.is_integer():\n",
    "            pop_size = int(pop_size)\n",
    "        else:\n",
    "            raise Exception(\"\"\"pop_size must be a positive integer.\"\"\")\n",
    "\n",
    "    if (keep_pct < 0) or (keep_pct > 1):\n",
    "        raise Exception(\"\"\"keep_pct must be between 0 and 1.\"\"\")\n",
    "\n",
    "    if (not isinstance(max_attempts, int) and not max_attempts.is_integer()) \\\n",
    "       or (max_attempts < 0):\n",
    "        raise Exception(\"\"\"max_attempts must be a positive integer.\"\"\")\n",
    "\n",
    "    if (not isinstance(max_iters, int) and max_iters != np.inf\n",
    "            and not max_iters.is_integer()) or (max_iters < 0):\n",
    "        raise Exception(\"\"\"max_iters must be a positive integer.\"\"\")\n",
    "\n",
    "    # Set random seed\n",
    "    if isinstance(random_state, int) and random_state > 0:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    if curve:\n",
    "        fitness_curve = []\n",
    "\n",
    "    if fast_mimic not in (True, False):\n",
    "        raise Exception(\"\"\"fast_mimic mode must be a boolean.\"\"\")\n",
    "    else:\n",
    "        problem.mimic_speed = fast_mimic\n",
    "\n",
    "    # Initialize problem, population and attempts counter\n",
    "    problem.reset()\n",
    "    problem.random_pop(pop_size)\n",
    "    attempts = 0\n",
    "    iters = 0\n",
    "\n",
    "    while (attempts < max_attempts) and (iters < max_iters):\n",
    "        iters += 1\n",
    "\n",
    "        # Get top n percent of population\n",
    "        problem.find_top_pct(keep_pct)\n",
    "\n",
    "        # Update probability estimates\n",
    "        problem.eval_node_probs()\n",
    "\n",
    "        # Generate new sample\n",
    "        new_sample = problem.sample_pop(pop_size)\n",
    "        problem.set_population(new_sample)\n",
    "\n",
    "        next_state = problem.best_child()\n",
    "\n",
    "        next_fitness = problem.eval_fitness(next_state)\n",
    "\n",
    "        # If best child is an improvement,\n",
    "        # move to that state and reset attempts counter\n",
    "        if next_fitness > problem.get_fitness():\n",
    "            problem.set_state(next_state)\n",
    "            attempts = 0\n",
    "\n",
    "        else:\n",
    "            attempts += 1\n",
    "\n",
    "        if curve:\n",
    "            fitness_curve.append(problem.get_fitness())\n",
    "\n",
    "    best_fitness = problem.get_maximize()*problem.get_fitness()\n",
    "    best_state = problem.get_state().astype(int)\n",
    "\n",
    "    if curve:\n",
    "        return best_state, best_fitness, np.asarray(fitness_curve)\n",
    "\n",
    "    return best_state, best_fitness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
